### Kafka UI

#### Condukor: Demo

* So I just want to show you how Conduktor works as a UI just so you can get the full power of it. So again, to get started if you need to, you go to our website and click on Try for free. If you sign up on your account, you'll get access to what we call the conduktor playground, which is what I'm going to show you. If you prefer to explore our demo environment, just put your email here and do access demo and you'll be able to access a Conduktor online with some real data. And finally, if you are a Docker person, you prefer to run everything locally, we have something for you to just follow these instructions right here and you'll be good to go to connect either to your remote cluster or to do some configuration to connect to a local cluster. So hopefully you're good to go. But so Conduktor is made of different products and console is the one that you will have the first usage for. But the more you go into your Kafka journey, the more you would want to use some additional products such as testing to test your Kafka applications, admin to start adding people onto the platform and start collaborating with others on some security stuff. For example, monitoring to connect to your Kafka and actually have a look at whether or not all the metrics look good. Data masking if you need to hide sensitive data, which is very helpful for GDPR, for example. Topic analyzer to analyze and discover insights about your topic and optimizations and topic as a service to really standardize your process and learn how to promote applications from dev to prod and so on. So quite a lot. But in this lecture I'm just going to show you the console. So the console is what you would expect it to be so you can create the topics and specify whatever topic configuration you want. And on top of it you can tag topics. So it's possible for you to add tags to find topics easier. So if it's like a development topic, you just say developments and you create this new tag, you can add colors and then you can say my topic demo. And create this topic. So if you go back to your topic list now, you will see that there is a tag development and you can also specify advanced configurations and so on. So we really allow you to do anything you would do with the CLI but with a UI. Now when you go into a topic, for example, if I go into my first topic and process some messages, as we can see there here, so by default we consume everything in your topic and you can have strong filtering capability such as show for most recent or a specific offset or a specific timeline, and you can filter the data in real time. And should you click to a specific message, you can view the message itself. So the key, the value as well as the headers, but we haven't specified any headers so far and the metadata, the partition, the offsets and so on. So it's pretty cool and we infer the key and value serializer. Now a good feature is that if you have a message you really like in your topic and you want to resend it, you can reprocess the message and reprocess it and send it to the same topic, so the first topic. So this brings us to the second tab where you can actually produce and in this case the produce get pre-filled with my previous data, the data that was right here with my key and my value. And this is why you see name and values Stephane already done. So you can just produce the message which will send it to Apache Kafka, but you can also generate some message, some random stuff. So you can see by clicking on generate once I've sent, I've created a new message and if I just don't specify anything, I should be good to go. Okay. So we produce this. Okay. The key is null and the value is whatever. And you can also specify headers if you wanted to. You can also specify that you want to send more than one records at a time with a random value or random key. And then you can have an automatic saying that every one second I want to send some messages. So if you have random value of automatic every one second and start to produce and it will stop after 60 seconds, as you can see, messages are being sent over time. So a very, very powerful way to customize any kind of producer you want very directly from conduktor console and some additional options. If you wanted to force partitions or specify a compression type or define different acks level. Configuration represents the configuration of your topic and you can see what has been override or everything. Consumer groups represents which consumer groups are assigned to the first topic. Schemas is when you use the schema registry, which is a component asset of Kafka and ACL is when you use Kafka security. So we've seen consumer group. This is where we can view all the consumer groups in our cluster and you can click on one and we can reset the offsets based on a strategy that we defined so extremely powerful and we can visualize a consumer group itself, look at the topics, look at the host and so on. Kafka Connect is for Kafka Connect. We'll learn about this later In this course. Brokers is to look at all the brokers in your cluster. So what are the addresses? What is the size of your broker, the number of partitions, those queue and so on. So this makes a lot of sense when you have your own cluster and you want to get some information into each broker as well as the logs and so on. So okay. And finally we have the ACLs. So ACLs is access control list. So this is when you start using security in Apache Kafka, where you define who can produce or consume which topics, and we create these ACLs for you and we can manage them from within Conduktor, which is very helpful. Now if you're using a company's playground so you have your own playground, but you also have a company playground, you can manage the team and by managing the team you can start adding your colleagues so you can invite a new member. And by inviting a new member, you can actually send it so that other people can use and see the Kafka data in your organization. You can also define roles. So who is an admin, a member, an editor and reviewer? So this defines different permissions for the actions from within Conduktors, so we really enhance the Kafka security. The audit log gives you information to who did what and when, so that you have full compliance needs filled on Apache Kafka and you can define cluster configuration. So this is my playground and my Kafka beginners course playground, but I can create my own cluster with whatever name and connect to whatever bootstrap server I want over any kind of security mechanism. And we've even built some very advanced features so that you have a certificate manager for SSL, for example. If you're new to Kafka, you don't need to know what that is. But just so you know, Conduktor really allows you to connect to any kind of cluster as you want. So that's it for a quick overview, I just wanted to give you proper tools that you can get started with when doing Apache Kafka and you're able to be accompanied all along the way when you have your own Kafka clusters.